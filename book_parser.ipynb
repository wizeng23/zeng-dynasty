{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e5c060",
   "metadata": {},
   "source": [
    "Main notebook :3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feffa4c",
   "metadata": {},
   "source": [
    "# Get pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ad8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_image, save_image, show_image, remove_small_islands, get_corners, normalize_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEMPLATE = \"book1/original/{}.png\"\n",
    "idx = -1 # skip first page\n",
    "for i in range(3, 12):\n",
    "    print(f\"i: {i}\")\n",
    "    filepath = PATH_TEMPLATE.format(f\"{i}\")\n",
    "    a = get_image(filepath)\n",
    "    a = remove_small_islands(a)\n",
    "    rows, cols = a.shape\n",
    "    # Find starting pixel of page border\n",
    "    i = int(rows / 2)\n",
    "    j = cols - 20\n",
    "    while a[i][j] or a[i][j - 1] or a[i][j - 2] or a[i][j - 3]:\n",
    "        j -= 1\n",
    "    right_page_corners = get_corners(a, i, j)\n",
    "    print(\"right_page_corners\", right_page_corners)\n",
    "    right_page = normalize_page(a, right_page_corners)\n",
    "    save_image(right_page, f\"book1/pages/{idx}.png\")\n",
    "    idx += 1\n",
    "\n",
    "    i = int(rows / 2)\n",
    "    j = 0\n",
    "    while a[i][j] or a[i][j + 1] or a[i][j + 2] or a[i][j + 3]:\n",
    "        j += 1\n",
    "    left_page_corners = get_corners(a, i, j)\n",
    "    print(\"left_page_corners\", left_page_corners)\n",
    "    left_page = normalize_page(a, left_page_corners)\n",
    "    save_image(left_page, f\"book1/pages/{idx}.png\")\n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEMPLATE = \"book2/original/{}.png\"\n",
    "idx = -1\n",
    "for i in range(68):\n",
    "    print(f\"i: {i}\")\n",
    "    filepath = PATH_TEMPLATE.format(f\"{i}\")\n",
    "    a = get_image(filepath)\n",
    "    a = remove_small_islands(a)\n",
    "    rows, cols = a.shape\n",
    "    # Find starting pixel of page border\n",
    "    i = int(rows / 2)\n",
    "    j = cols - 20\n",
    "    while a[i][j] or a[i][j - 1] or a[i][j - 2] or a[i][j - 3]:\n",
    "        j -= 1\n",
    "    right_page_corners = get_corners(a, i, j)\n",
    "    print(\"right_page_corners\", right_page_corners)\n",
    "    right_page = normalize_page(a, right_page_corners)\n",
    "    save_image(right_page, f\"book2/pages/{idx}.png\")\n",
    "    idx += 1\n",
    "\n",
    "    i = int(rows / 2)\n",
    "    j = 0\n",
    "    while a[i][j] or a[i][j + 1] or a[i][j + 2] or a[i][j + 3]:\n",
    "        j += 1\n",
    "    left_page_corners = get_corners(a, i, j)\n",
    "    print(\"left_page_corners\", left_page_corners)\n",
    "    left_page = normalize_page(a, left_page_corners)\n",
    "    save_image(left_page, f\"book2/pages/{idx}.png\")\n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a45bb",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d606f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import trim_borders, shrink_page\n",
    "\n",
    "PATH_TEMPLATE = \"book1/pages/{}.png\"\n",
    "for i in range(17):\n",
    "    print(f\"i: {i}\")\n",
    "    filepath = PATH_TEMPLATE.format(i)\n",
    "    a = get_image(filepath)\n",
    "    a = trim_borders(a)\n",
    "    a = shrink_page(a)\n",
    "    save_image(a, f\"book1/graphs/{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ed54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import trim_borders, shrink_page, is_tree_start_page, merge_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEMPLATE = \"book1/pages/{}.png\"\n",
    "pages = []\n",
    "is_page_tree_start = []\n",
    "for i in range(17):\n",
    "    filepath = PATH_TEMPLATE.format(i)\n",
    "    a = get_image(filepath)\n",
    "    a = trim_borders(a)\n",
    "    is_page_tree_start.append(is_tree_start_page(a))\n",
    "    a = shrink_page(a)\n",
    "    pages.append(a)\n",
    "#   save_image(a, f\"book1/graphs/{i}.png\")\n",
    "\n",
    "print(\"Merging and saving graphs\")\n",
    "i = 0\n",
    "while i < 17:\n",
    "    start_i = i\n",
    "    graph = pages[i]\n",
    "    i += 1\n",
    "    while i < 17 and not is_page_tree_start[i]:\n",
    "        print(f\"---------Merge starting at i: {i}\")\n",
    "        left = pages[i]\n",
    "        graph = merge_graphs(left, graph)\n",
    "        i += 1\n",
    "    save_image(graph, f\"book1/graphs/{start_i}_{i-1}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15741d6",
   "metadata": {},
   "source": [
    "# Graph parsing heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527016ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dataclasses\n",
    "import json\n",
    "from utils import find_lines, find_line_ends, Node, sort_nodes, infer_ends, verify_nodes, get_name_image, print_trees\n",
    "from data.node import Node as DataNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb911d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_files = sorted(os.listdir(\"book1/graphs\"), key=lambda x: int(x.split('_')[0]) if x.endswith('.png') else 0)\n",
    "print(graph_files)\n",
    "node_idx = 1\n",
    "\n",
    "data_file = open(\"data/book1.jsonl\", \"w\")\n",
    "\n",
    "for filepath in graph_files:\n",
    "    if not filepath.endswith(\".png\"):\n",
    "        continue\n",
    "    filename = os.path.splitext(filepath)[0]\n",
    "    a = get_image(os.path.join(\"book1/graphs\", filepath))\n",
    "    raw_results = find_lines(a)\n",
    "    results = []\n",
    "    for raw_result in raw_results:\n",
    "        parents, children = find_line_ends(raw_result)\n",
    "        if len(parents) != 1:\n",
    "            raise ValueError(\"More than one parent found\", parents)\n",
    "        parent = parents[0]\n",
    "        results.append((parent, children))\n",
    "        print(parent, children)\n",
    "\n",
    "    nodes = []\n",
    "    for parent, children in results:\n",
    "        pn = Node(bot=parent)\n",
    "        nodes.append(pn)\n",
    "        for c in children:\n",
    "            cn = Node(top=c)\n",
    "            pn.children.append(cn)\n",
    "            nodes.append(cn)\n",
    "    print(\"Num nodes pre merge:\", len(nodes))\n",
    "\n",
    "    # Merge nodes\n",
    "    while True:\n",
    "        made_progress = False\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(len(nodes)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                p = nodes[i]\n",
    "                c = nodes[j]\n",
    "                # print(p, c)\n",
    "                # Only try the connection is p is missing bot and c is missing top\n",
    "                if p.bot or c.top:\n",
    "                    continue\n",
    "                # print(\"valid\")\n",
    "                tx, ty = p.top\n",
    "                bx, by = c.bot\n",
    "                if 0 < bx - tx < 200 and abs(by - ty) < 20:\n",
    "                    # print(\"merge\")\n",
    "                    # Same node, merge\n",
    "                    p.bot = c.bot\n",
    "                    p.children = c.children\n",
    "                    del nodes[j]\n",
    "                    made_progress = True\n",
    "                    break\n",
    "            if made_progress:\n",
    "                break\n",
    "        if not made_progress:\n",
    "            break\n",
    "\n",
    "    print(\"Num nodes post merge:\", len(nodes))\n",
    "    infer_ends(nodes, a)\n",
    "    verify_nodes(nodes)\n",
    "\n",
    "    # Give nodes globally unique ids\n",
    "    nodes = sort_nodes(nodes)\n",
    "    for n in nodes:\n",
    "        n.id = node_idx\n",
    "        node_idx += 1\n",
    "\n",
    "    idx = 0\n",
    "    tree = {}\n",
    "    c2p = {}\n",
    "    for n in nodes:\n",
    "        for c in n.children:\n",
    "            c2p[c.id] = n.id\n",
    "    node_to_idx = {(n.top, n.bot): i for i, n in enumerate(nodes)}\n",
    "    for n in nodes:\n",
    "        tree[node_to_idx[(n.top, n.bot)]] = [\n",
    "            node_to_idx[(c.top, c.bot)] for c in n.children\n",
    "        ]\n",
    "        name_img = get_name_image(n, a)\n",
    "        data_node = DataNode(\n",
    "            id=n.id,\n",
    "            name_images=[f\"book1/names/{n.id}.png\"],\n",
    "            generation=-1,\n",
    "            parent=c2p[n.id] if n.id in c2p else -1,\n",
    "            children=[c.id for c in n.children],\n",
    "            notes=f\"{filename}_{idx}\"\n",
    "        )\n",
    "        data_file.write(json.dumps(dataclasses.asdict(data_node)) + \"\\n\")\n",
    "        save_image(name_img, f\"book1/names/{n.id}.png\")\n",
    "        idx += 1\n",
    "    json.dump(tree, open(f\"book1/trees/{filename}.json\", \"w\"))\n",
    "\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85408d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge adjacent pages if their lines go off the edge (and if they're missing the tag). Warn on orphans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13_37.png looks sus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a4f06",
   "metadata": {},
   "source": [
    "# Graph parsing opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e335ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "img = get_image(\"book1/cropped/0.png\")\n",
    "lines = cv2.HoughLinesP(\n",
    "    1-img,\n",
    "    rho=1,\n",
    "    theta=math.pi/180,\n",
    "    threshold=10,\n",
    "    minLineLength=60,\n",
    "    maxLineGap=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b548173",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.squeeze().tolist()\n",
    "# Swap coordinates if x1+y1 > x2+y2 to ensure consistent ordering\n",
    "for line in lines:\n",
    "    line[0], line[1], line[2], line[3] = line[1], line[0], line[3], line[2]\n",
    "    if line[0] + line[1] > line[2] + line[3]:\n",
    "        line[0], line[1], line[2], line[3] = line[2], line[3], line[0], line[1]\n",
    "\n",
    "lines = sorted(lines, key=lambda x: x[0])\n",
    "\n",
    "def deduplicate_lines(lines, threshold=10):\n",
    "  \"\"\"\n",
    "  Deduplicate a 2D list where entries are considered duplicates\n",
    "  if all corresponding values are within the threshold.\n",
    "  \"\"\"\n",
    "  if not lines:\n",
    "    return []\n",
    "  \n",
    "  deduplicated = []\n",
    "  \n",
    "  for line in lines:\n",
    "    is_duplicate = False\n",
    "    for existing in deduplicated:\n",
    "      # Check if all corresponding values are within threshold\n",
    "      if all(abs(line[i] - existing[i]) <= threshold for i in range(len(line))):\n",
    "        is_duplicate = True\n",
    "        break\n",
    "    \n",
    "    if not is_duplicate:\n",
    "      deduplicated.append(line)\n",
    "  \n",
    "  return deduplicated\n",
    "\n",
    "lines = deduplicate_lines(lines)\n",
    "for line in lines:\n",
    "  line2 = [line[1], line[0], line[3], line[2]]\n",
    "  print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lines.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d932caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x1, y1, x2, y2) in lines[:, 0]:\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0,0,255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(1-img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)\n",
    "print(centroids)\n",
    "print(num_labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aff66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, stat in enumerate(stats):\n",
    "    x, y, w, h, area = stat\n",
    "    if area > 50:  # adjust threshold\n",
    "        name_img = img[y:y+h, x:x+w]\n",
    "        save_image(name_img, f\"names/name_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833c532",
   "metadata": {},
   "source": [
    "# attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Optional blur to reduce noise\n",
    "blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "# Binary inverse threshold — black border becomes white\n",
    "_, thresh = cv2.threshold(blur, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort contours by area (largest first)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_corners = []\n",
    "\n",
    "for cnt in contours[:2]:  # take top 2 (two pages)\n",
    "    # Approximate contour to polygon\n",
    "    peri = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "    print(approx)\n",
    "    print(len(approx))\n",
    "\n",
    "    if len(approx) == 4:\n",
    "        corners = approx.reshape(4, 2)\n",
    "        page_corners.append(corners)\n",
    "\n",
    "# Visualize results\n",
    "vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "for corners in page_corners:\n",
    "    for x, y in corners:\n",
    "        cv2.circle(vis, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imwrite(\"detected_corners.png\", vis)\n",
    "\n",
    "\n",
    "# Sort each corner set to TL, TR, BR, BL order\n",
    "def order_points(pts):\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "    tr = pts[np.argmin(diff)]\n",
    "    bl = pts[np.argmax(diff)]\n",
    "    return np.array([tl, tr, br, bl], dtype=np.float32)\n",
    "\n",
    "\n",
    "ordered_pages = [order_points(c) for c in page_corners]\n",
    "\n",
    "for i, corners in enumerate(ordered_pages):\n",
    "    print(f\"Page {i + 1} corners (TL, TR, BR, BL):\\n\", corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordered_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339690a9",
   "metadata": {},
   "source": [
    "# CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f067f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"data/zeng_google_sheet.csv\", keep_default_na=False)\n",
    "df[\"id\"] = df[\"id\"].astype(int)\n",
    "df[\"name_images\"] = [[]] * len(df)\n",
    "df[\"generation\"] = df[\"generation\"].astype(int)\n",
    "df[\"parent\"] = df[\"parent\"].astype(int)\n",
    "df[\"children\"] = df[\"children\"].apply(\n",
    "    lambda x: [int(child) for child in x.split(\",\")] if x else []\n",
    ")\n",
    "\n",
    "# Iterate through rows and set parent based on children relationships\n",
    "for _, row in df.iterrows():\n",
    "    # Get the current node's ID and its children\n",
    "    node_id = row[\"id\"]\n",
    "    children = row[\"children\"]\n",
    "\n",
    "    # For each child, set its parent to the current node_id\n",
    "    for child_id in children:\n",
    "        df.loc[df[\"id\"] == child_id, \"parent\"] = node_id\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame to JSONL format\n",
    "df.to_json(\"data/book1.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4100e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/book1.jsonl\", \"r\") as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "\n",
    "print(records[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
