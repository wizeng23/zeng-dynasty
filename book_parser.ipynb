{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e5c060",
   "metadata": {},
   "source": [
    "Main notebook :3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feffa4c",
   "metadata": {},
   "source": [
    "# Get pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678ad8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_image, save_image, show_image, remove_small_islands, get_corners, normalize_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4a8846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 3\n",
      "right_page_corners ((127, 1909), (110, 3182), (2043, 3199), (2059, 1927))\n",
      "left_page_corners ((133, 425), (147, 1705), (2089, 1682), (2079, 402))\n",
      "i: 4\n",
      "right_page_corners ((131, 1915), (110, 3190), (2039, 3213), (2060, 1939))\n",
      "left_page_corners ((128, 441), (141, 1721), (2080, 1697), (2069, 416))\n",
      "i: 5\n",
      "right_page_corners ((128, 1897), (107, 3170), (2046, 3194), (2065, 1922))\n",
      "left_page_corners ((126, 427), (137, 1707), (2073, 1688), (2064, 405))\n",
      "i: 6\n",
      "right_page_corners ((124, 1903), (103, 3175), (2041, 3199), (2060, 1926))\n",
      "left_page_corners ((127, 436), (138, 1716), (2072, 1696), (2062, 414))\n",
      "i: 7\n",
      "right_page_corners ((132, 1890), (112, 3163), (2047, 3185), (2065, 1912))\n",
      "left_page_corners ((128, 423), (142, 1704), (2081, 1682), (2070, 401))\n",
      "i: 8\n",
      "right_page_corners ((126, 1898), (105, 3173), (2036, 3194), (2054, 1919))\n",
      "left_page_corners ((133, 433), (142, 1713), (2083, 1696), (2077, 416))\n",
      "i: 9\n",
      "right_page_corners ((127, 1893), (109, 3166), (2044, 3186), (2058, 1912))\n",
      "left_page_corners ((134, 426), (140, 1707), (2079, 1694), (2075, 413))\n",
      "i: 10\n",
      "right_page_corners ((119, 1894), (104, 3167), (2043, 3183), (2055, 1909))\n",
      "left_page_corners ((130, 437), (141, 1717), (2076, 1698), (2067, 416))\n",
      "i: 11\n",
      "right_page_corners ((124, 1877), (103, 3151), (2043, 3173), (2060, 1899))\n",
      "left_page_corners ((221, 428), (225, 1701), (2105, 1697), (2105, 422))\n"
     ]
    }
   ],
   "source": [
    "PATH_TEMPLATE = \"book1/original/{}.png\"\n",
    "idx = -1 # skip first page\n",
    "for i in range(3, 12):\n",
    "    print(f\"i: {i}\")\n",
    "    filepath = PATH_TEMPLATE.format(f\"{i}\")\n",
    "    a = get_image(filepath)\n",
    "    a = remove_small_islands(a)\n",
    "    rows, cols = a.shape\n",
    "    # Find starting pixel of page border\n",
    "    i = int(rows / 2)\n",
    "    j = cols - 20\n",
    "    while a[i][j] or a[i][j - 1] or a[i][j - 2] or a[i][j - 3]:\n",
    "        j -= 1\n",
    "    right_page_corners = get_corners(a, i, j)\n",
    "    print(\"right_page_corners\", right_page_corners)\n",
    "    right_page = normalize_page(a, right_page_corners)\n",
    "    save_image(right_page, f\"book1/pages/{idx}.png\")\n",
    "    idx += 1\n",
    "\n",
    "    i = int(rows / 2)\n",
    "    j = 0\n",
    "    while a[i][j] or a[i][j + 1] or a[i][j + 2] or a[i][j + 3]:\n",
    "        j += 1\n",
    "    left_page_corners = get_corners(a, i, j)\n",
    "    print(\"left_page_corners\", left_page_corners)\n",
    "    left_page = normalize_page(a, left_page_corners)\n",
    "    save_image(left_page, f\"book1/pages/{idx}.png\")\n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a45bb",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d606f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import trim_borders, shrink_page\n",
    "\n",
    "PATH_TEMPLATE = \"book1/pages/{}.png\"\n",
    "for i in range(17):\n",
    "    print(f\"i: {i}\")\n",
    "    filepath = PATH_TEMPLATE.format(i)\n",
    "    a = get_image(filepath)\n",
    "    a = trim_borders(a)\n",
    "    a = shrink_page(a)\n",
    "    save_image(a, f\"book1/graphs/{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ed54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import trim_borders, shrink_page, is_tree_start_page, merge_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1581aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging and saving graphs\n",
      "---------Merge starting at i: 14\n",
      "Left x, right x\n",
      "[537] [548]\n",
      "Adjusted left x, right x\n",
      "[548] [548]\n",
      "---------Merge starting at i: 15\n",
      "Left x, right x\n",
      "[863, 1237, 1523] [860, 1245, 1536]\n",
      "Adjusted left x, right x\n",
      "[863, 1237, 1523] [863, 1248, 1539]\n",
      "---------Merge starting at i: 16\n",
      "Left x, right x\n",
      "[884] [863, 1236]\n",
      "Adjusted left x, right x\n",
      "[884] [884, 1257]\n",
      "!!!!!!!!!!!!!!!!!!Orphans [1257] on right side\n"
     ]
    }
   ],
   "source": [
    "PATH_TEMPLATE = \"book1/pages/{}.png\"\n",
    "pages = []\n",
    "is_page_tree_start = []\n",
    "for i in range(17):\n",
    "    filepath = PATH_TEMPLATE.format(i)\n",
    "    a = get_image(filepath)\n",
    "    a = trim_borders(a)\n",
    "    is_page_tree_start.append(is_tree_start_page(a))\n",
    "    a = shrink_page(a)\n",
    "    pages.append(a)\n",
    "#   save_image(a, f\"book1/graphs/{i}.png\")\n",
    "\n",
    "print(\"Merging and saving graphs\")\n",
    "i = 0\n",
    "while i < 17:\n",
    "    start_i = i\n",
    "    graph = pages[i]\n",
    "    i += 1\n",
    "    while i < 17 and not is_page_tree_start[i]:\n",
    "        print(f\"---------Merge starting at i: {i}\")\n",
    "        left = pages[i]\n",
    "        graph = merge_graphs(left, graph)\n",
    "        i += 1\n",
    "    save_image(graph, f\"book1/graphs/{start_i}_{i-1}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15741d6",
   "metadata": {},
   "source": [
    "# Graph parsing heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527016ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dataclasses\n",
    "import json\n",
    "from utils import find_lines, find_line_ends, Node, sort_nodes, infer_ends, verify_nodes, get_name_image, print_trees\n",
    "from data.node import Node as DataNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb911d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '0_0.png', '1_1.png', '2_2.png', '3_3.png', '4_4.png', '5_5.png', '6_6.png', '7_7.png', '8_8.png', '9_9.png', '10_10.png', '11_11.png', '12_12.png', '13_16.png']\n",
      "(130, 241) [(367, 241)]\n",
      "(445, 241) [(681, 33), (681, 138), (681, 240)]\n",
      "(760, 241) [(992, 240)]\n",
      "(1072, 241) [(1306, 240)]\n",
      "(1387, 240) [(1622, 240)]\n",
      "Num nodes pre merge: 12\n",
      "Num nodes post merge: 8\n",
      "start bot 881\n",
      "start bot 881\n",
      "start bot 1698\n",
      "min_y 7 max_y 70\n",
      "min_x 0 max_x 59\n",
      "min_y 6 max_y 75\n",
      "min_x 0 max_x 67\n",
      "min_y 1 max_y 66\n",
      "min_x 4 max_x 64\n",
      "min_y 12 max_y 67\n",
      "min_x 2 max_x 64\n",
      "min_y 5 max_y 73\n",
      "min_x 6 max_x 64\n",
      "min_y 9 max_y 70\n",
      "min_x 8 max_x 66\n",
      "min_y 5 max_y 75\n",
      "min_x 8 max_x 69\n",
      "min_y 11 max_y 66\n",
      "min_x 8 max_x 65\n",
      "(131, 141) [(364, 140)]\n",
      "(443, 140) [(678, 139)]\n",
      "(760, 140) [(999, 36), (999, 139)]\n",
      "(1081, 139) [(1318, 139)]\n",
      "(1400, 140) [(1631, 139)]\n",
      "Num nodes pre merge: 11\n",
      "Num nodes post merge: 7\n",
      "start bot 1199\n",
      "start bot 1707\n",
      "min_y 7 max_y 59\n",
      "min_x 0 max_x 57\n",
      "min_y 10 max_y 71\n",
      "min_x 0 max_x 68\n",
      "min_y 5 max_y 74\n",
      "min_x 8 max_x 67\n",
      "min_y 1 max_y 68\n",
      "min_x 6 max_x 61\n",
      "min_y 5 max_y 69\n",
      "min_x 3 max_x 71\n",
      "min_y 10 max_y 66\n",
      "min_x 8 max_x 70\n",
      "min_y 6 max_y 72\n",
      "min_x 7 max_x 65\n",
      "(131, 244) [(369, 36), (369, 243)]\n",
      "(446, 244) [(673, 244)]\n",
      "(754, 244) [(987, 141), (987, 244)]\n",
      "(1067, 244) [(1305, 243)]\n",
      "(1388, 244) [(1624, 243)]\n",
      "Num nodes pre merge: 12\n",
      "Num nodes post merge: 8\n",
      "start bot 569\n",
      "start bot 1187\n",
      "start bot 1701\n",
      "min_y 5 max_y 72\n",
      "min_x 0 max_x 59\n",
      "min_y 1 max_y 68\n",
      "min_x 0 max_x 56\n",
      "min_y 3 max_y 73\n",
      "min_x 0 max_x 64\n",
      "min_y 4 max_y 71\n",
      "min_x 2 max_x 70\n",
      "min_y 5 max_y 68\n",
      "min_x 5 max_x 62\n",
      "min_y 7 max_y 69\n",
      "min_x 2 max_x 69\n",
      "min_y 3 max_y 75\n",
      "min_x 7 max_x 71\n",
      "min_y 4 max_y 73\n",
      "min_x 10 max_x 66\n",
      "(133, 546) [(371, 442), (371, 544)]\n",
      "(449, 446) [(683, 445)]\n",
      "(449, 545) [(682, 544)]\n",
      "(763, 445) [(996, 343), (996, 445)]\n",
      "(763, 544) [(995, 544)]\n",
      "(1075, 342) [(1311, 30), (1311, 341)]\n",
      "(1075, 545) [(1309, 543)]\n",
      "(1076, 445) [(1309, 444)]\n",
      "(1391, 341) [(1627, 136), (1627, 238), (1627, 341)]\n",
      "(1391, 445) [(1626, 444)]\n",
      "(1391, 543) [(1627, 543)]\n",
      "Num nodes pre merge: 27\n",
      "Num nodes post merge: 17\n",
      "start bot 1511\n",
      "start bot 1703\n",
      "start bot 1703\n",
      "start bot 1703\n",
      "start bot 1703\n",
      "start bot 1703\n",
      "min_y 8 max_y 75\n",
      "min_x 0 max_x 57\n",
      "min_y 9 max_y 77\n",
      "min_x 0 max_x 65\n",
      "min_y 15 max_y 71\n",
      "min_x 2 max_x 64\n",
      "min_y 7 max_y 75\n",
      "min_x 4 max_x 68\n",
      "min_y 8 max_y 78\n",
      "min_x 4 max_x 69\n",
      "min_y 8 max_y 71\n",
      "min_x 9 max_x 65\n",
      "min_y 10 max_y 70\n",
      "min_x 4 max_x 66\n",
      "min_y 8 max_y 76\n",
      "min_x 6 max_x 69\n",
      "min_y 1 max_y 67\n",
      "min_x 6 max_x 63\n",
      "min_y 8 max_y 74\n",
      "min_x 6 max_x 69\n",
      "min_y 6 max_y 72\n",
      "min_x 4 max_x 71\n",
      "min_y 10 max_y 77\n",
      "min_x 8 max_x 70\n",
      "min_y 5 max_y 73\n",
      "min_x 6 max_x 65\n",
      "min_y 5 max_y 75\n",
      "min_x 8 max_x 64\n",
      "min_y 10 max_y 71\n",
      "min_x 5 max_x 65\n",
      "min_y 5 max_y 73\n",
      "min_x 10 max_x 66\n",
      "min_y 8 max_y 76\n",
      "min_x 6 max_x 65\n",
      "(129, 237) [(363, 35), (363, 236)]\n",
      "(440, 236) [(669, 236)]\n",
      "(751, 236) [(990, 133), (990, 236)]\n",
      "(1072, 236) [(1309, 235)]\n",
      "(1392, 236) [(1627, 236)]\n",
      "Num nodes pre merge: 12\n",
      "Num nodes post merge: 8\n",
      "start bot 563\n",
      "start bot 1190\n",
      "start bot 1701\n",
      "min_y 8 max_y 79\n",
      "min_x 0 max_x 57\n",
      "min_y 1 max_y 69\n",
      "min_x 0 max_x 55\n",
      "min_y 11 max_y 79\n",
      "min_x 0 max_x 64\n",
      "min_y 19 max_y 78\n",
      "min_x 3 max_x 70\n",
      "min_y 10 max_y 79\n",
      "min_x 2 max_x 65\n",
      "min_y 10 max_y 79\n",
      "min_x 1 max_x 71\n",
      "min_y 10 max_y 79\n",
      "min_x 8 max_x 69\n",
      "min_y 12 max_y 79\n",
      "min_x 7 max_x 63\n",
      "(132, 242) [(370, 241)]\n",
      "(450, 242) [(687, 241)]\n",
      "(769, 242) [(1004, 241)]\n",
      "(1083, 242) [(1313, 138), (1313, 241)]\n",
      "(1393, 135) [(1626, 32), (1626, 135)]\n",
      "Num nodes pre merge: 12\n",
      "Num nodes post merge: 8\n",
      "start bot 1513\n",
      "start bot 1753\n",
      "start bot 1753\n",
      "min_y 6 max_y 73\n",
      "min_x 0 max_x 58\n",
      "min_y 5 max_y 74\n",
      "min_x 0 max_x 67\n",
      "min_y 8 max_y 73\n",
      "min_x 5 max_x 68\n",
      "min_y 4 max_y 73\n",
      "min_x 6 max_x 68\n",
      "min_y 6 max_y 74\n",
      "min_x 4 max_x 69\n",
      "min_y 5 max_y 74\n",
      "min_x 7 max_x 62\n",
      "min_y 1 max_y 67\n",
      "min_x 8 max_x 116\n",
      "min_y 8 max_y 75\n",
      "min_x 7 max_x 114\n",
      "(174, 337) [(362, 337)]\n",
      "(437, 341) [(670, 341)]\n",
      "(753, 341) [(993, 238), (993, 340)]\n",
      "(1074, 237) [(1312, 39), (1312, 236)]\n",
      "(1392, 238) [(1627, 134), (1627, 236)]\n",
      "Num nodes pre merge: 13\n",
      "Num nodes post merge: 9\n",
      "start bot 1193\n",
      "start bot 1512\n",
      "start bot 1757\n",
      "start bot 1757\n",
      "min_y 12 max_y 78\n",
      "min_x 0 max_x 108\n",
      "min_y 10 max_y 79\n",
      "min_x 0 max_x 62\n",
      "min_y 13 max_y 76\n",
      "min_x 7 max_x 69\n",
      "min_y 7 max_y 73\n",
      "min_x 5 max_x 69\n",
      "min_y 10 max_y 75\n",
      "min_x 2 max_x 65\n",
      "min_y 1 max_y 65\n",
      "min_x 8 max_x 60\n",
      "min_y 12 max_y 75\n",
      "min_x 4 max_x 69\n",
      "min_y 10 max_y 73\n",
      "min_x 6 max_x 119\n",
      "min_y 11 max_y 74\n",
      "min_x 5 max_x 114\n",
      "(179, 344) [(370, 343)]\n",
      "(498, 343) [(690, 31), (690, 240), (690, 342)]\n",
      "(817, 241) [(1007, 239)]\n",
      "(1085, 241) [(1317, 138), (1317, 240)]\n",
      "(1394, 140) [(1624, 140)]\n",
      "Num nodes pre merge: 13\n",
      "Num nodes post merge: 9\n",
      "start bot 890\n",
      "start bot 890\n",
      "start bot 1517\n",
      "start bot 1755\n",
      "min_y 8 max_y 72\n",
      "min_x 0 max_x 113\n",
      "min_y 6 max_y 74\n",
      "min_x 0 max_x 117\n",
      "min_y 1 max_y 69\n",
      "min_x 2 max_x 112\n",
      "min_y 7 max_y 75\n",
      "min_x 3 max_x 116\n",
      "min_y 8 max_y 76\n",
      "min_x 2 max_x 113\n",
      "min_y 12 max_y 72\n",
      "min_x 4 max_x 65\n",
      "min_y 7 max_y 72\n",
      "min_x 8 max_x 64\n",
      "min_y 7 max_y 75\n",
      "min_x 5 max_x 62\n",
      "min_y 3 max_y 73\n",
      "min_x 6 max_x 120\n",
      "(175, 962) [(368, 35), (368, 135), (368, 243), (368, 345), (368, 962)]\n",
      "(442, 960) [(679, 959)]\n",
      "(809, 961) [(998, 651), (998, 961)]\n",
      "(1076, 649) [(1310, 544), (1310, 647)]\n",
      "(1076, 959) [(1310, 855), (1310, 958)]\n",
      "(1389, 857) [(1624, 754), (1624, 857)]\n",
      "(1389, 958) [(1624, 958)]\n",
      "(1390, 546) [(1625, 441), (1625, 545)]\n",
      "(1390, 649) [(1624, 649)]\n",
      "Num nodes pre merge: 27\n",
      "Num nodes post merge: 19\n",
      "start bot 568\n",
      "start bot 568\n",
      "start bot 568\n",
      "start bot 568\n",
      "start bot 1754\n",
      "start bot 1754\n",
      "start bot 1754\n",
      "start bot 1754\n",
      "start bot 1754\n",
      "start bot 1754\n",
      "min_y 5 max_y 76\n",
      "min_x 0 max_x 113\n",
      "min_y 1 max_y 69\n",
      "min_x 0 max_x 56\n",
      "min_y 9 max_y 72\n",
      "min_x 1 max_x 52\n",
      "min_y 6 max_y 69\n",
      "min_x 0 max_x 55\n",
      "min_y 4 max_y 72\n",
      "min_x 2 max_x 53\n",
      "min_y 4 max_y 72\n",
      "min_x 1 max_x 60\n",
      "min_y 6 max_y 77\n",
      "min_x 3 max_x 119\n",
      "min_y 7 max_y 71\n",
      "min_x 2 max_x 67\n",
      "min_y 4 max_y 75\n",
      "min_x 2 max_x 65\n",
      "min_y 15 max_y 74\n",
      "min_x 6 max_x 69\n",
      "min_y 10 max_y 79\n",
      "min_x 4 max_x 69\n",
      "min_y 9 max_y 72\n",
      "min_x 4 max_x 68\n",
      "min_y 12 max_y 75\n",
      "min_x 6 max_x 67\n",
      "min_y 10 max_y 79\n",
      "min_x 4 max_x 67\n",
      "min_y 10 max_y 78\n",
      "min_x 8 max_x 62\n",
      "min_y 7 max_y 78\n",
      "min_x 5 max_x 67\n",
      "min_y 5 max_y 75\n",
      "min_x 7 max_x 65\n",
      "min_y 6 max_y 76\n",
      "min_x 7 max_x 66\n",
      "min_y 9 max_y 78\n",
      "min_x 6 max_x 119\n",
      "(179, 38) [(368, 37)]\n",
      "Num nodes pre merge: 2\n",
      "Num nodes post merge: 2\n",
      "start bot 433\n",
      "min_y 1 max_y 70\n",
      "min_x 0 max_x 113\n",
      "min_y 1 max_y 69\n",
      "min_x 0 max_x 54\n",
      "(131, 37) [(369, 36)]\n",
      "Num nodes pre merge: 2\n",
      "Num nodes post merge: 2\n",
      "start bot 439\n",
      "min_y 1 max_y 72\n",
      "min_x 0 max_x 59\n",
      "min_y 3 max_y 70\n",
      "min_x 0 max_x 59\n",
      "(124, 139) [(359, 36), (359, 138)]\n",
      "Num nodes pre merge: 3\n",
      "Num nodes post merge: 3\n",
      "start bot 439\n",
      "start bot 439\n",
      "min_y 6 max_y 74\n",
      "min_x 0 max_x 53\n",
      "min_y 1 max_y 66\n",
      "min_x 7 max_x 69\n",
      "min_y 5 max_y 72\n",
      "min_x 9 max_x 69\n",
      "(131, 236) [(368, 235)]\n",
      "(445, 235) [(674, 235)]\n",
      "(753, 236) [(985, 235)]\n",
      "(1067, 235) [(1306, 235)]\n",
      "(1388, 235) [(1625, 36), (1625, 132), (1625, 235)]\n",
      "Num nodes pre merge: 12\n",
      "Num nodes post merge: 8\n",
      "start bot 1703\n",
      "start bot 1703\n",
      "start bot 1703\n",
      "min_y 12 max_y 79\n",
      "min_x 0 max_x 64\n",
      "min_y 12 max_y 79\n",
      "min_x 0 max_x 66\n",
      "min_y 16 max_y 79\n",
      "min_x 5 max_x 68\n",
      "min_y 14 max_y 78\n",
      "min_x 4 max_x 71\n",
      "min_y 12 max_y 78\n",
      "min_x 7 max_x 70\n",
      "min_y 1 max_y 69\n",
      "min_x 9 max_x 67\n",
      "min_y 12 max_y 79\n",
      "min_x 7 max_x 67\n",
      "min_y 10 max_y 79\n",
      "min_x 9 max_x 67\n",
      "(158, 3525) [(395, 3525)]\n",
      "(474, 3526) [(708, 2572), (708, 3525)]\n",
      "(786, 2569) [(1026, 135), (1026, 343), (1026, 2368), (1026, 2568)]\n",
      "(787, 3525) [(1021, 3220), (1021, 3525)]\n",
      "(1116, 342) [(1358, 237), (1358, 341)]\n",
      "(1117, 131) [(1358, 28), (1358, 131)]\n",
      "(1155, 2570) [(1348, 2466), (1348, 2569)]\n",
      "(1207, 3216) [(1344, 2709), (1344, 2809), (1344, 2909), (1344, 3215)]\n",
      "(1207, 3530) [(1344, 3530)]\n",
      "(1211, 2362) [(1350, 542), (1350, 850), (1350, 1157), (1350, 1362), (1350, 1639), (1350, 1851), (1350, 2158), (1350, 2361)]\n",
      "(1462, 3217) [(1652, 3018), (1652, 3116), (1652, 3217)]\n",
      "(1465, 849) [(1655, 642), (1655, 746), (1655, 849)]\n",
      "(1466, 1161) [(1655, 953), (1655, 1058), (1655, 1160)]\n",
      "(1466, 1365) [(1655, 1262), (1655, 1365)]\n",
      "(1471, 2809) [(1658, 2808)]\n",
      "(1471, 2909) [(1659, 2908)]\n",
      "(1480, 1642) [(1670, 1467), (1670, 1642)]\n",
      "(1480, 1848) [(1670, 1746), (1670, 1848)]\n",
      "(1480, 2149) [(1671, 1952), (1671, 2047), (1671, 2149)]\n",
      "(1480, 2361) [(1671, 2258), (1671, 2360)]\n",
      "(1480, 2465) [(1670, 2465)]\n",
      "(1525, 3530) [(1659, 3321), (1659, 3428), (1659, 3529)]\n",
      "Num nodes pre merge: 76\n",
      "Num nodes post merge: 55\n",
      "start bot 1558\n",
      "start bot 1558\n",
      "start bot 1558\n",
      "start bot 1558\n",
      "start bot 1548\n",
      "start bot 1544\n",
      "start bot 1550\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "start bot 1835\n",
      "min_y 9 max_y 79\n",
      "min_x 0 max_x 61\n",
      "min_y 14 max_y 77\n",
      "min_x 0 max_x 65\n",
      "min_y 7 max_y 70\n",
      "min_x 3 max_x 64\n",
      "min_y 16 max_y 78\n",
      "min_x 7 max_x 61\n",
      "min_y 10 max_y 77\n",
      "min_x 4 max_x 72\n",
      "min_y 12 max_y 74\n",
      "min_x 4 max_x 70\n",
      "min_y 2 max_y 69\n",
      "min_x 0 max_x 174\n",
      "min_y 8 max_y 77\n",
      "min_x 0 max_x 118\n",
      "min_y 8 max_y 71\n",
      "min_x 2 max_x 173\n",
      "min_y 12 max_y 77\n",
      "min_x 2 max_x 173\n",
      "min_y 1 max_y 67\n",
      "min_x 0 max_x 109\n",
      "min_y 14 max_y 79\n",
      "min_x 0 max_x 109\n",
      "min_y 9 max_y 79\n",
      "min_x 0 max_x 108\n",
      "min_y 10 max_y 79\n",
      "min_x 0 max_x 107\n",
      "min_y 5 max_y 74\n",
      "min_x 0 max_x 96\n",
      "min_y 6 max_y 75\n",
      "min_x 0 max_x 101\n",
      "min_y 7 max_y 76\n",
      "min_x 0 max_x 102\n",
      "min_y 7 max_y 77\n",
      "min_x 0 max_x 102\n",
      "min_y 11 max_y 78\n",
      "min_x 0 max_x 117\n",
      "min_y 3 max_y 71\n",
      "min_x 4 max_x 116\n",
      "min_y 5 max_y 74\n",
      "min_x 3 max_x 116\n",
      "min_y 8 max_y 77\n",
      "min_x 0 max_x 116\n",
      "min_y 7 max_y 75\n",
      "min_x 2 max_x 118\n",
      "min_y 7 max_y 76\n",
      "min_x 1 max_x 112\n",
      "min_y 1 max_y 71\n",
      "min_x 0 max_x 107\n",
      "min_y 6 max_y 73\n",
      "min_x 0 max_x 113\n",
      "min_y 9 max_y 76\n",
      "min_x 0 max_x 113\n",
      "min_y 12 max_y 79\n",
      "min_x 0 max_x 107\n",
      "min_y 5 max_y 70\n",
      "min_x 0 max_x 169\n",
      "min_y 7 max_y 76\n",
      "min_x 0 max_x 109\n",
      "min_y 6 max_y 75\n",
      "min_x 0 max_x 107\n",
      "min_y 6 max_y 74\n",
      "min_x 0 max_x 108\n",
      "min_y 5 max_y 74\n",
      "min_x 0 max_x 110\n",
      "min_y 3 max_y 71\n",
      "min_x 0 max_x 111\n",
      "min_y 4 max_y 72\n",
      "min_x 0 max_x 110\n",
      "min_y 5 max_y 74\n",
      "min_x 0 max_x 111\n",
      "min_y 4 max_y 74\n",
      "min_x 0 max_x 112\n",
      "min_y 5 max_y 75\n",
      "min_x 0 max_x 98\n",
      "min_y 7 max_y 74\n",
      "min_x 0 max_x 110\n",
      "min_y 6 max_y 73\n",
      "min_x 0 max_x 113\n",
      "min_y 6 max_y 74\n",
      "min_x 0 max_x 108\n",
      "min_y 5 max_y 73\n",
      "min_x 0 max_x 113\n",
      "min_y 13 max_y 79\n",
      "min_x 0 max_x 109\n",
      "min_y 14 max_y 79\n",
      "min_x 0 max_x 109\n",
      "min_y 7 max_y 76\n",
      "min_x 0 max_x 110\n",
      "min_y 9 max_y 78\n",
      "min_x 0 max_x 114\n",
      "min_y 7 max_y 76\n",
      "min_x 0 max_x 102\n",
      "min_y 5 max_y 76\n",
      "min_x 1 max_x 114\n",
      "min_y 8 max_y 78\n",
      "min_x 3 max_x 112\n",
      "min_y 1 max_y 71\n",
      "min_x 7 max_x 119\n",
      "min_y 5 max_y 77\n",
      "min_x 5 max_x 120\n",
      "min_y 8 max_y 79\n",
      "min_x 8 max_x 120\n",
      "min_y 8 max_y 75\n",
      "min_x 0 max_x 165\n",
      "min_y 6 max_y 70\n",
      "min_x 0 max_x 165\n",
      "min_y 5 max_y 74\n",
      "min_x 0 max_x 114\n"
     ]
    }
   ],
   "source": [
    "graph_files = sorted(os.listdir(\"book1/graphs\"), key=lambda x: int(x.split('_')[0]) if x.endswith('.png') else 0)\n",
    "print(graph_files)\n",
    "node_idx = 1\n",
    "\n",
    "data_file = open(\"data/book1.jsonl\", \"w\")\n",
    "\n",
    "for filepath in graph_files:\n",
    "    if not filepath.endswith(\".png\"):\n",
    "        continue\n",
    "    filename = os.path.splitext(filepath)[0]\n",
    "    a = get_image(os.path.join(\"book1/graphs\", filepath))\n",
    "    raw_results = find_lines(a)\n",
    "    results = []\n",
    "    for raw_result in raw_results:\n",
    "        parents, children = find_line_ends(raw_result)\n",
    "        if len(parents) != 1:\n",
    "            raise ValueError(\"More than one parent found\", parents)\n",
    "        parent = parents[0]\n",
    "        results.append((parent, children))\n",
    "        print(parent, children)\n",
    "\n",
    "    nodes = []\n",
    "    for parent, children in results:\n",
    "        pn = Node(bot=parent)\n",
    "        nodes.append(pn)\n",
    "        for c in children:\n",
    "            cn = Node(top=c)\n",
    "            pn.children.append(cn)\n",
    "            nodes.append(cn)\n",
    "    print(\"Num nodes pre merge:\", len(nodes))\n",
    "\n",
    "    # Merge nodes\n",
    "    while True:\n",
    "        made_progress = False\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(len(nodes)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                p = nodes[i]\n",
    "                c = nodes[j]\n",
    "                # print(p, c)\n",
    "                # Only try the connection is p is missing bot and c is missing top\n",
    "                if p.bot or c.top:\n",
    "                    continue\n",
    "                # print(\"valid\")\n",
    "                tx, ty = p.top\n",
    "                bx, by = c.bot\n",
    "                if 0 < bx - tx < 200 and abs(by - ty) < 20:\n",
    "                    # print(\"merge\")\n",
    "                    # Same node, merge\n",
    "                    p.bot = c.bot\n",
    "                    p.children = c.children\n",
    "                    del nodes[j]\n",
    "                    made_progress = True\n",
    "                    break\n",
    "            if made_progress:\n",
    "                break\n",
    "        if not made_progress:\n",
    "            break\n",
    "\n",
    "    print(\"Num nodes post merge:\", len(nodes))\n",
    "    infer_ends(nodes, a)\n",
    "    verify_nodes(nodes)\n",
    "\n",
    "    # Give nodes globally unique ids\n",
    "    nodes = sort_nodes(nodes)\n",
    "    for n in nodes:\n",
    "        n.id = node_idx\n",
    "        node_idx += 1\n",
    "\n",
    "    idx = 0\n",
    "    tree = {}\n",
    "    c2p = {}\n",
    "    for n in nodes:\n",
    "        for c in n.children:\n",
    "            c2p[c.id] = n.id\n",
    "    node_to_idx = {(n.top, n.bot): i for i, n in enumerate(nodes)}\n",
    "    for n in nodes:\n",
    "        tree[node_to_idx[(n.top, n.bot)]] = [\n",
    "            node_to_idx[(c.top, c.bot)] for c in n.children\n",
    "        ]\n",
    "        name_img = get_name_image(n, a)\n",
    "        data_node = DataNode(\n",
    "            id=n.id,\n",
    "            name_images=[f\"book1/names/{n.id}.png\"],\n",
    "            generation=-1,\n",
    "            parent=c2p[n.id] if n.id in c2p else -1,\n",
    "            children=[c.id for c in n.children],\n",
    "            notes=f\"{filename}_{idx}\"\n",
    "        )\n",
    "        data_file.write(json.dumps(dataclasses.asdict(data_node)) + \"\\n\")\n",
    "        save_image(name_img, f\"book1/names/{n.id}.png\")\n",
    "        idx += 1\n",
    "    json.dump(tree, open(f\"book1/trees/{filename}.json\", \"w\"))\n",
    "\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85408d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge adjacent pages if their lines go off the edge (and if they're missing the tag). Warn on orphans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13_37.png looks sus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a4f06",
   "metadata": {},
   "source": [
    "# Graph parsing opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e335ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "img = get_image(\"book1/cropped/0.png\")\n",
    "lines = cv2.HoughLinesP(\n",
    "    1-img,\n",
    "    rho=1,\n",
    "    theta=math.pi/180,\n",
    "    threshold=10,\n",
    "    minLineLength=60,\n",
    "    maxLineGap=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b548173",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.squeeze().tolist()\n",
    "# Swap coordinates if x1+y1 > x2+y2 to ensure consistent ordering\n",
    "for line in lines:\n",
    "    line[0], line[1], line[2], line[3] = line[1], line[0], line[3], line[2]\n",
    "    if line[0] + line[1] > line[2] + line[3]:\n",
    "        line[0], line[1], line[2], line[3] = line[2], line[3], line[0], line[1]\n",
    "\n",
    "lines = sorted(lines, key=lambda x: x[0])\n",
    "\n",
    "def deduplicate_lines(lines, threshold=10):\n",
    "  \"\"\"\n",
    "  Deduplicate a 2D list where entries are considered duplicates\n",
    "  if all corresponding values are within the threshold.\n",
    "  \"\"\"\n",
    "  if not lines:\n",
    "    return []\n",
    "  \n",
    "  deduplicated = []\n",
    "  \n",
    "  for line in lines:\n",
    "    is_duplicate = False\n",
    "    for existing in deduplicated:\n",
    "      # Check if all corresponding values are within threshold\n",
    "      if all(abs(line[i] - existing[i]) <= threshold for i in range(len(line))):\n",
    "        is_duplicate = True\n",
    "        break\n",
    "    \n",
    "    if not is_duplicate:\n",
    "      deduplicated.append(line)\n",
    "  \n",
    "  return deduplicated\n",
    "\n",
    "lines = deduplicate_lines(lines)\n",
    "for line in lines:\n",
    "  line2 = [line[1], line[0], line[3], line[2]]\n",
    "  print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lines.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d932caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x1, y1, x2, y2) in lines[:, 0]:\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0,0,255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(1-img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)\n",
    "print(centroids)\n",
    "print(num_labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aff66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, stat in enumerate(stats):\n",
    "    x, y, w, h, area = stat\n",
    "    if area > 50:  # adjust threshold\n",
    "        name_img = img[y:y+h, x:x+w]\n",
    "        save_image(name_img, f\"names/name_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833c532",
   "metadata": {},
   "source": [
    "# attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Optional blur to reduce noise\n",
    "blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "# Binary inverse threshold — black border becomes white\n",
    "_, thresh = cv2.threshold(blur, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Sort contours by area (largest first)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_corners = []\n",
    "\n",
    "for cnt in contours[:2]:  # take top 2 (two pages)\n",
    "    # Approximate contour to polygon\n",
    "    peri = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "    print(approx)\n",
    "    print(len(approx))\n",
    "\n",
    "    if len(approx) == 4:\n",
    "        corners = approx.reshape(4, 2)\n",
    "        page_corners.append(corners)\n",
    "\n",
    "# Visualize results\n",
    "vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "for corners in page_corners:\n",
    "    for x, y in corners:\n",
    "        cv2.circle(vis, (int(x), int(y)), 10, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imwrite(\"detected_corners.png\", vis)\n",
    "\n",
    "\n",
    "# Sort each corner set to TL, TR, BR, BL order\n",
    "def order_points(pts):\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "    tr = pts[np.argmin(diff)]\n",
    "    bl = pts[np.argmax(diff)]\n",
    "    return np.array([tl, tr, br, bl], dtype=np.float32)\n",
    "\n",
    "\n",
    "ordered_pages = [order_points(c) for c in page_corners]\n",
    "\n",
    "for i, corners in enumerate(ordered_pages):\n",
    "    print(f\"Page {i + 1} corners (TL, TR, BR, BL):\\n\", corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ordered_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339690a9",
   "metadata": {},
   "source": [
    "# CSV Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f067f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"data/zeng_google_sheet.csv\", keep_default_na=False)\n",
    "df[\"id\"] = df[\"id\"].astype(int)\n",
    "df[\"name_images\"] = [[]] * len(df)\n",
    "df[\"generation\"] = df[\"generation\"].astype(int)\n",
    "df[\"parent\"] = df[\"parent\"].astype(int)\n",
    "df[\"children\"] = df[\"children\"].apply(\n",
    "    lambda x: [int(child) for child in x.split(\",\")] if x else []\n",
    ")\n",
    "\n",
    "# Iterate through rows and set parent based on children relationships\n",
    "for _, row in df.iterrows():\n",
    "    # Get the current node's ID and its children\n",
    "    node_id = row[\"id\"]\n",
    "    children = row[\"children\"]\n",
    "\n",
    "    # For each child, set its parent to the current node_id\n",
    "    for child_id in children:\n",
    "        df.loc[df[\"id\"] == child_id, \"parent\"] = node_id\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame to JSONL format\n",
    "df.to_json(\"data/book1.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4100e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/book1.jsonl\", \"r\") as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "\n",
    "print(records[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
